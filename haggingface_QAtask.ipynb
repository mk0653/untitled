{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "haggingface_QAtask.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMNxlMtiT4htOSFFapD3sbX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mk0653/untitled/blob/master/haggingface_QAtask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou3O1_7HiRvL",
        "outputId": "63d81414-915d-4daf-9cc9-48da4e2828db"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.96)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.0rc4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "767UbUC34V35",
        "outputId": "0553091b-6d23-4401-a4b5-c6ad97b51767"
      },
      "source": [
        "pip install transformers[\"ja\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers[ja] in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "\u001b[33m  WARNING: transformers 3.0.0 does not provide the extra 'ja'\u001b[0m\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (0.1.96)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (20.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (0.0.45)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (0.8.0rc4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[ja]) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers[ja]) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[ja]) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[ja]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[ja]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[ja]) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[ja]) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[ja]) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[ja]) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_U_-RW_49Cf",
        "outputId": "4ce27abd-8829-4529-fc1a-cb83afb5c9cb"
      },
      "source": [
        "pip install fugashi[unidic-lite]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fugashi[unidic-lite] in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: unidic-lite; extra == \"unidic-lite\" in /usr/local/lib/python3.7/dist-packages (from fugashi[unidic-lite]) (1.0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PjcHAIR5c9c",
        "outputId": "c21b4541-b1af-4688-d235-a54e096cd9ae"
      },
      "source": [
        "pip install ipadic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipadic in /usr/local/lib/python3.7/dist-packages (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feRae1kbAYhz"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "import torch\n",
        "\n",
        "# ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\", return_dict=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umtO86NEhFp-"
      },
      "source": [
        "\n",
        "# ãƒ†ã‚­ã‚¹ãƒˆ\n",
        "text = r\"\"\"\n",
        "ğŸ¤— Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides general-purpose\n",
        "architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNetâ€¦) for Natural Language Understanding (NLU) and Natural\n",
        "Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between\n",
        "TensorFlow 2.0 and PyTorch.\n",
        "\"\"\"\n",
        "# ğŸ¤— Transformers(æ—§ç§°ï¼špytorch-transformersã€pytorch-pretrained-bert)ã¯ã€\n",
        "# è‡ªç„¶è¨€èªç†è§£ï¼ˆNLUï¼‰ã¨è‡ªç„¶è¨€èªç”Ÿæˆï¼ˆNLGï¼‰ã®ãŸã‚ã®æ±ç”¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£\n",
        "# ï¼ˆBERTã€GPT-2ã€RoBERTaã€XLMã€DistilBertã€XLNet...ï¼‰ã‚’100ä»¥ä¸Šã®è¨€èªã§\n",
        "# 32ä»¥ä¸Šã®äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¨\n",
        "# TensorFlow 2.0ã¨PyTorchã®é–“ã®ç›¸äº’é‹ç”¨æ€§ã‚’æä¾›ã—ã¾ã™ã€‚\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKUGkK4GhGcX"
      },
      "source": [
        "# è³ªå•\n",
        "questions = [\n",
        "    \"How many pretrained models are available in Transformers?\",\n",
        "    \"What does Transformers provide?\",\n",
        "    \"Transformers provides interoperability between which frameworks?\",\n",
        "]\n",
        "# Transformersã«ã¯ä½•ç¨®é¡ã®äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ã®ã‹ï¼Ÿ\n",
        "# Transformersã¯ä½•ã‚’æä¾›ã—ã¦ã„ã‚‹ã®ã‹ï¼Ÿ\n",
        "# Transformersã¯ã©ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é–“ã®ç›¸äº’é‹ç”¨æ€§ã‚’æä¾›ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF_XetAshMuc",
        "outputId": "3e8a152b-14ee-4d5c-8a9a-d0d9ccfea85c"
      },
      "source": [
        "\n",
        "for question in questions:\n",
        "    # å‰å‡¦ç†\n",
        "    inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "\n",
        "    # æ¨è«–\n",
        "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "    answer_start_scores, answer_end_scores = model(**inputs)\n",
        "\n",
        "    # å¯èƒ½æ€§ã®é«˜ã„å›ç­”ã®å–å¾—\n",
        "    answer_start = torch.argmax(answer_start_scores)  \n",
        "    answer_end = torch.argmax(answer_end_scores) + 1 \n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
        "\n",
        "    # å‡ºåŠ›\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Answer: {answer}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question: How many pretrained models are available in Transformers?\n",
            "Answer: over 32 +\n",
            "\n",
            "Question: What does Transformers provide?\n",
            "Answer: general - purpose architectures\n",
            "\n",
            "Question: Transformers provides interoperability between which frameworks?\n",
            "Answer: tensorflow 2. 0 and pytorch\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWWH95j0lpGg"
      },
      "source": [
        "text_news = r\"\"\"\n",
        "The collapsed condominium in Florida, southern United States, has been aging for 40 years since it was built, and a preliminary survey of the renovation work revealed that multiple cracks were found in the pillars and other parts.\n",
        "More than two days have passed since an accident in which a part of a 12-story condominium collapsed near Miami in Florida, USA, and five people were confirmed dead.\n",
        "It is not clear how many people were in the building when the condominium collapsed, but according to local authorities, 156 of the residents were out of contact and were searched by rescue teams. The activity is continuing.\n",
        "\"\"\"\n",
        "#ã‚¢ãƒ¡ãƒªã‚«å—éƒ¨ãƒ•ãƒ­ãƒªãƒ€å·ã§å´©è½ã—ãŸãƒãƒ³ã‚·ãƒ§ãƒ³ã¯ã€å»ºè¨­ã•ã‚Œã¦ã‹ã‚‰ã“ã¨ã—ã§40å¹´ã¨è€æœ½åŒ–ã—ã¦ã„ã¦ã€æ”¹ä¿®å·¥äº‹ã«ã‚€ã‘ãŸäº‹å‰ã®èª¿æŸ»ã§ã¯æŸ±ãªã©ã«è¤‡æ•°ã®äº€è£‚ãŒè¦‹ã¤ã‹ã£ã¦ã„ãŸã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚\n",
        "#ã‚¢ãƒ¡ãƒªã‚«å—éƒ¨ãƒ•ãƒ­ãƒªãƒ€å·ã®ãƒã‚¤ã‚¢ãƒŸè¿‘éƒŠã§12éšå»ºã¦ã®ãƒãƒ³ã‚·ãƒ§ãƒ³ã®ä¸€éƒ¨ãŒå´©ã‚Œè½ã¡ã€5äººã®æ­»äº¡ãŒç¢ºèªã•ã‚Œã¦ã„ã‚‹äº‹æ•…ãŒèµ·ãã¦ã‹ã‚‰2æ—¥ä½™ã‚ŠãŒçµŒéã—ã¾ã—ãŸã€‚\n",
        "#ãƒãƒ³ã‚·ãƒ§ãƒ³ãŒå´©ã‚ŒãŸã¨ãã«ä½•äººãŒå»ºç‰©å†…ã«ã„ãŸã®ã‹ã¯æ˜ã‚‰ã‹ã«ãªã£ã¦ã„ã¾ã›ã‚“ãŒã€åœ°å…ƒå½“å±€ã«ã‚ˆã‚Šã¾ã™ã¨ã€å±…ä½è€…ã®ã†ã¡é€£çµ¡ãŒã¨ã‚Œãªããªã£ã¦ã„ã‚‹äººã¯156äººã«ã®ã¼ã£ã¦ã„ã¦ã€æ•‘åŠ©éšŠã«ã‚ˆã‚‹æœç´¢æ´»å‹•ãŒç¶šã‘ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqGG2Gn0nQ2V"
      },
      "source": [
        "# è³ªå•\n",
        "questions = [\n",
        "    \"What kind of accident is it?\",\n",
        "    \"What is the cause of the accident?\",\n",
        "    \"Are there any deaths?\",\n",
        "]\n",
        "\n",
        "#ã©ã®ã‚ˆã†ãªäº‹æ•…ã§ã™ã‹ï¼Ÿ\n",
        "#äº‹æ•…ã®åŸå› ã¯ä½•ã§ã™ã‹ï¼Ÿ\n",
        "#æ­»äº¡è€…ã¯ã„ã¾ã™ã‹ï¼Ÿ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4QMPYhD-rn5",
        "outputId": "76ca59e3-2dc1-4f40-b71f-fe9189b88738"
      },
      "source": [
        "\n",
        "for question in questions:\n",
        "    # å‰å‡¦ç†\n",
        "    inputs = tokenizer.encode_plus(question, text_news, add_special_tokens=True, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "\n",
        "    # æ¨è«–\n",
        "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "    answer_start_scores, answer_end_scores = model(**inputs)\n",
        "\n",
        "    # å¯èƒ½æ€§ã®é«˜ã„å›ç­”ã®å–å¾—\n",
        "    answer_start = torch.argmax(answer_start_scores)  \n",
        "    answer_end = torch.argmax(answer_end_scores) + 1 \n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
        "\n",
        "    # å‡ºåŠ›\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Answer: {answer}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question: What kind of accident is it?\n",
            "Answer: an accident in which a part of a 12 - story condominium collapsed\n",
            "\n",
            "Question: What is the cause of the accident?\n",
            "Answer: multiple cracks\n",
            "\n",
            "Question: Are there any deaths?\n",
            "Answer: five people were confirmed dead\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B38bsNuh-sPM"
      },
      "source": [
        "æ—¥æœ¬èªã®bertãƒ¢ãƒ‡ãƒ«ã§ã®æ¤œè¨¼ã€‚äº‹å‰å­¦ç¿’ã®ã¿ã§QAã‚¿ã‚¹ã‚¯ç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr1mUcZ-nw_J",
        "outputId": "410a4cae-7b8f-4310-bb17-a229d1f28c86"
      },
      "source": [
        "from transformers import BertJapaneseTokenizer, AutoModelForQuestionAnswering\n",
        "import torch\n",
        "\n",
        "# å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ\n",
        "context = r\"\"\"\n",
        "åƒè‘‰çœŒå…«è¡—å¸‚ã‚’ç®¡è½„ã™ã‚‹æ¶ˆé˜²ãªã©ã«ã‚ˆã‚Šã¾ã™ã¨ã€28æ—¥åˆå¾Œ3æ™‚åŠã”ã‚ã€å…«è¡—å¸‚å…«è¡—ã®è·¯ä¸Šã§ãƒˆãƒ©ãƒƒã‚¯ãŒå°å­¦ç”Ÿã®åˆ—ã«çªã£è¾¼ã¿ã¾ã—ãŸã€‚è­¦å¯Ÿã¨æ¶ˆé˜²ã«ã‚ˆã‚Šã¾ã™ã¨ã€ï¼’äººãŒå¿ƒè‚ºåœæ­¢ã®çŠ¶æ…‹ã§ï¼“äººãŒé‡å‚·ã ã¨ã„ã†ã“ã¨ã§ã™ã€‚\n",
        "\"\"\"\n",
        "question=\"é‡å‚·è€…ã¯ä½•åï¼Ÿ\"\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')  \n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking') \n",
        "\n",
        "# æ¨è«–ã®å®Ÿè¡Œ\n",
        "inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
        "input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "output = model(**inputs)\n",
        "answer_start = torch.argmax(output.start_logits)  \n",
        "answer_end = torch.argmax(output.end_logits) + 1 \n",
        "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
        "\n",
        "# çµæœå‡ºåŠ›\n",
        "print(\"è³ªå•: \"+question)\n",
        "print(\"å¿œç­”: \"+answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "è³ªå•: é‡å‚·è€…ã¯ä½•åï¼Ÿ\n",
            "å¿œç­”: \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}